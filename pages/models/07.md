---
layout: default
---

# Structured Output

<div class="text-sm mt-6">

<v-click>

<div class="mb-4">

**Problema:** Las respuestas de LLMs son texto plano, difíciles de procesar

**Solución:** Forzar al modelo a responder con JSON estructurado

</div>

</v-click>

<v-click>

```typescript
import { ChatOpenAI } from "@langchain/openai";
import { z } from "zod";

// Definir el esquema con Zod
const schema = z.object({
  sentiment: z.enum(["positive", "negative", "neutral"]),
  score: z.number().min(0).max(1),
  keywords: z.array(z.string()),
});

const model = new ChatOpenAI({ model: "gpt-4o-mini" })
  .withStructuredOutput(schema);

const result = await model.invoke("Me encanta LangChain!");
// { sentiment: "positive", score: 0.95, keywords: ["encanta", "langchain"] }
```

</v-click>

</div>
